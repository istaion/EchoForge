from typing import Dict, Any, List, Optional, Tuple
from langchain.agents import create_react_agent, AgentExecutor, AgentType
from langchain.tools import Tool, BaseTool
from langchain_core.prompts import PromptTemplate
from langchain_core.language_models import BaseLanguageModel
from pydantic import BaseModel, Field
import json
from echoforge.agents.state.character_state import CharacterState
from echoforge.core.llm_providers import LLMManager
from echoforge.core import EchoForgeRAG
from echoforge.utils.config import get_config
from langsmith import traceable
import re


class SearchWorldKnowledgeTool(BaseTool):
    """Tool pour rechercher dans les connaissances du monde"""
    name:str = "search_world"
    description:str = "Recherche dans les connaissances g√©n√©rales du monde et de l'√Æle. Utilise pour : histoire, lieux, √©v√©nements globaux."
    rag_system: Any
    evaluate_tool: Any  # R√©f√©rence √† l'outil d'√©valuation
    
    def _run(self, query: str) -> str:
        """Execute the tool"""
        try:
            print(f"üîç Recherche dans world_lore avec query: '{query}'")
            results = self.rag_system.retrieve_world_context(query, top_k=5)
            
            # Formater pour l'affichage
            if results:
                print(f"üìÑ {len(results)} documents trouv√©s")
                for r in results[:3]:  # Afficher les 3 premiers
                    print(f"  - {r[:80]}...")
            
            # Convertir en format structur√© pour l'agent
            formatted_results = []
            for i, content in enumerate(results):
                formatted_results.append({
                    "content": content,
                    "source": "world_knowledge",
                    "relevance": "high" if i == 0 else "medium"
                })
            
            # IMPORTANT: Mettre √† jour _last_results sur l'instance evaluate_tool
            if self.evaluate_tool:
                self.evaluate_tool._last_results = formatted_results
                self.evaluate_tool._last_source = "world"
            
            return json.dumps(formatted_results, ensure_ascii=False)
            
        except Exception as e:
            return f"Erreur lors de la recherche: {str(e)}"

class SearchCharacterKnowledgeTool(BaseTool):
    """Tool pour rechercher dans les connaissances du personnage"""
    name:str = "search_character"
    description:str = "Recherche dans les connaissances personnelles du personnage. Utilise pour : souvenirs, relations, secrets personnels, enfance."
    rag_system: Any
    character_name: str
    evaluate_tool: Any  # R√©f√©rence √† l'outil d'√©valuation
    
    def _run(self, query: str) -> str:
        """Execute the tool"""
        try:
            print(f"üîç Recherche dans character_{self.character_name} avec query: '{query}'")
            results = self.rag_system.retrieve_character_context(
                query, self.character_name.lower(), top_k=5
            )
            
            # Formater pour l'affichage
            if results:
                print(f"üìÑ {len(results)} documents trouv√©s")
                for r in results[:3]:  # Afficher les 3 premiers
                    print(f"  - {r[:80]}...")
            
            # Convertir en format structur√©
            formatted_results = []
            for i, content in enumerate(results):
                formatted_results.append({
                    "content": content,
                    "source": f"{self.character_name}_knowledge",
                    "relevance": "high" if i == 0 else "medium"
                })
            
            # IMPORTANT: Mettre √† jour _last_results sur l'instance evaluate_tool
            if self.evaluate_tool:
                self.evaluate_tool._last_results = formatted_results
                self.evaluate_tool._last_source = "character"
            
            return json.dumps(formatted_results, ensure_ascii=False)
            
        except Exception as e:
            return f"Erreur lors de la recherche: {str(e)}"


class EvaluateRelevanceTool(BaseTool):
    """Tool pour √©valuer la pertinence des r√©sultats"""
    name:str = "evaluate_relevance"
    description:str = "√âvalue si les derniers r√©sultats de recherche sont suffisants pour r√©pondre. Ne prend aucun param√®tre."
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._last_results = None
        self._last_source = None
    
    def _run(self, query: str = "") -> str:
        """Execute the tool - accepte un argument optionnel mais ne l'utilise pas"""
        if not self._last_results:
            return "none - aucune recherche effectu√©e"
        
        # √âvaluer la pertinence
        high_relevance_count = sum(1 for r in self._last_results if r.get("relevance") == "high")
        total_results = len(self._last_results)
        
        if high_relevance_count > 0:
            return f"sufficient - informations pertinentes trouv√©es ({self._last_source})"
        elif total_results > 0:
            return f"partial - quelques informations trouv√©es mais peu pertinentes ({self._last_source})"
        else:
            return "insufficient - aucune information pertinente trouv√©e"
    
    async def _arun(self, query: str = "") -> str:
        return self._run(query)
    
    def reset(self):
        """R√©initialise les r√©sultats stock√©s"""
        self.last_results = None


class AnalyzeQuestionTool(BaseTool):
    """Tool pour analyser la question et extraire les concepts cl√©s"""
    name: str = "analyze_question"
    description: str = "Analyse la question pour identifier les concepts cl√©s et le type d'information recherch√©e."
    
    def _run(self, question: str) -> str:
        """Analyse la question"""
        # Analyse simple des mots-cl√©s et patterns
        keywords = []
        question_lower = question.lower()
        
        # Patterns de questions
        patterns = {
            "historical": ["histoire", "pass√©", "avant", "autrefois", "origine"],
            "relationship": ["relation", "ami", "ennemi", "famille", "connais"],
            "location": ["o√π", "lieu", "endroit", "trouve", "situ√©"],
            "personality": ["caract√®re", "personnalit√©", "comportement", "pourquoi", "toi", "enfance"],
            "action": ["faire", "peut", "capable", "donne", "aide"],
            "knowledge": ["sais", "connais", "explique", "raconte", "parle"]
        }
        
        detected_types = []
        for ptype, words in patterns.items():
            if any(word in question_lower for word in words):
                detected_types.append(ptype)
        
        # Extraction de mots-cl√©s importants
        important_words = [w for w in question.split() if len(w) > 3 and w.lower() not in ["pour", "avec", "dans", "mais"]]
        
        # D√©tection sp√©ciale pour questions personnelles
        needs_personal = any(word in question_lower for word in ["toi", "ton", "ta", "tes", "enfance", "pass√©"])
        
        return json.dumps({
            "question_types": detected_types,
            "keywords": important_words[:5],
            "needs_personal_info": needs_personal,
            "needs_world_info": "location" in detected_types or "historical" in detected_types
        }, ensure_ascii=False)
    
    async def _arun(self, question: str) -> str:
        return self._run(question)


def create_rag_agent_prompt() -> PromptTemplate:
    """Cr√©e le prompt pour l'agent RAG ReAct"""
    
    template = """Tu es un assistant de recherche intelligent pour le personnage {character_name}.
Ta mission est de d√©terminer si une recherche dans la base de connaissances est n√©cessaire et, si oui, de trouver les informations pertinentes.

Personnage actuel: {character_name}
Question de l'utilisateur: "{user_message}"
Intention d√©tect√©e: {intent}

Tu as acc√®s aux outils suivants:
{tools}

R√àGLES IMPORTANTES:
1. Pour les salutations et questions simples, tu peux directement donner la Final Answer sans utiliser d'outils
2. N'utilise les outils QUE si la question n√©cessite des connaissances sp√©cifiques
3. Apr√®s avoir analys√© la question, si c'est une salutation ou une question simple, passe directement √† la Final Answer

PROCESSUS DE D√âCISION:

1. D'abord, analyse mentalement si la question n√©cessite une recherche:
   - Salutations ("bonjour", "salut", etc.) ‚Üí Final Answer directe avec needs_rag: false
   - Questions simples (oui/non, √©motions basiques) ‚Üí Final Answer directe avec needs_rag: false
   - Questions sur l'histoire, relations, lieux, √©v√©nements ‚Üí Utilise les outils
   - Questions sur le personnage, son pass√©, ses connaissances ‚Üí Utilise les outils

2. Si recherche n√©cessaire:
   - Utilise analyze_question pour comprendre la question
   - Choisis le(s) bon(s) outil(s):
     * search_world pour : histoire de l'√Æle, lieux, √©v√©nements globaux
     * search_character pour : souvenirs personnels, enfance, relations, secrets
     * Tu peux utiliser les DEUX si la question touche aux deux aspects
   - Utilise evaluate_relevance (sans param√®tres) apr√®s TOUTES les recherches
   - Si insuffisant, reformule et recherche √† nouveau (max 3 tentatives)

3. Format de r√©ponse:
   - Si aucune recherche effectu√©e ‚Üí relevant_knowledge: []
   - Si recherche effectu√©e ‚Üí inclure TOUS les contenus pertinents trouv√©s

Utilise EXACTEMENT ce format:
Question: la question d'entr√©e
Thought: r√©flexion sur ce que tu dois faire
Action: l'action √† prendre, doit √™tre l'une de [{tool_names}]
Action Input: l'input de l'action
Observation: le r√©sultat de l'action
... (r√©p√®te si n√©cessaire)
Thought: Je connais maintenant la r√©ponse finale
Final Answer: {{
    "needs_rag": true/false,
    "search_performed": true/false,
    "relevant_knowledge": [],
    "search_queries": [],
    "evaluation": "none",
    "reasoning": "explication courte"
}}

EXEMPLE pour une salutation:
Question: Bonjour !
Thought: C'est une salutation simple qui ne n√©cessite pas de recherche dans la base de connaissances.
Final Answer: {{
    "needs_rag": false,
    "search_performed": false,
    "relevant_knowledge": [],
    "search_queries": [],
    "evaluation": "none",
    "reasoning": "Salutation simple ne n√©cessitant pas de recherche"
}}

EXEMPLE pour une question personnelle:
Question: Parle-moi de ton enfance
Thought: L'utilisateur demande des informations personnelles sur mon enfance. Je dois chercher dans mes connaissances personnelles.
Action: analyze_question
Action Input: "Parle-moi de ton enfance"
Observation: {{"question_types": ["personality", "knowledge"], "keywords": ["Parle-moi", "enfance"], "needs_personal_info": true, "needs_world_info": false}}

Thought: L'analyse confirme que c'est une question personnelle. Je dois rechercher dans mes souvenirs personnels.
Action: search_character
Action Input: "enfance pass√© souvenirs famille jeunesse"
Observation: [r√©sultats sur l'enfance du personnage]

Thought: J'ai trouv√© des informations sur mon enfance. Je dois √©valuer si c'est suffisant.
Action: evaluate_relevance
Action Input: 
Observation: sufficient - informations pertinentes trouv√©es (personnage)

Thought: Je connais maintenant la r√©ponse finale
Final Answer: {{
    "needs_rag": true,
    "search_performed": true,
    "relevant_knowledge": ["contenu sur l'enfance trouv√©"],
    "search_queries": ["enfance pass√© souvenirs famille jeunesse"],
    "evaluation": "sufficient",
    "reasoning": "Question personnelle sur l'enfance n√©cessitant des recherches dans les souvenirs du personnage"
}}

EXEMPLE pour une question mixte:
Question: Comment ton enfance sur l'√Æle t'a-t-elle influenc√©?
Thought: Cette question touche √† la fois l'enfance personnelle ET l'histoire de l'√Æle. Je dois rechercher dans les deux.
Action: search_character
Action Input: "enfance influence personnalit√© formation"
Observation: [r√©sultats personnels]

Thought: J'ai des infos personnelles, mais je dois aussi chercher sur l'√Æle.
Action: search_world  
Action Input: "√Æle histoire √©v√©nements p√©riode enfance"
Observation: [r√©sultats sur l'√Æle]

Thought: J'ai maintenant des infos des deux sources. V√©rifions si c'est suffisant.
Action: evaluate_relevance
Action Input:
Observation: sufficient - informations pertinentes trouv√©es (personnage et monde)

Thought: Je connais maintenant la r√©ponse finale
Final Answer: {{
    "needs_rag": true,
    "search_performed": true,
    "relevant_knowledge": ["infos enfance personnage", "contexte historique √Æle"],
    "search_queries": ["enfance influence personnalit√© formation", "√Æle histoire √©v√©nements p√©riode enfance"],
    "evaluation": "sufficient",
    "reasoning": "Question mixte n√©cessitant des recherches personnelles et contextuelles"
}}

Commence!

Question: {user_message}
{agent_scratchpad}"""
    
    return PromptTemplate(
        template=template,
        input_variables=["character_name", "user_message", "intent", "tools", "tool_names", "agent_scratchpad"]
    )


class ReactRAGAgent:
    """Agent ReAct pour g√©rer intelligemment les recherches RAG"""
    
    def __init__(self, llm_manager: LLMManager, rag_system: EchoForgeRAG):
        self.llm_manager = llm_manager
        self.llm = llm_manager.get_llm()
        self.rag_system = rag_system
        self.config = get_config()
    
    @traceable
    def process_rag_need(
        self,
        user_message: str,
        character_name: str,
        intent: str,
        conversation_history: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Traite le besoin de RAG et effectue les recherches si n√©cessaire.
        """
        # Cr√©er les tools
        evaluate_tool = EvaluateRelevanceTool()
        tools = [
            AnalyzeQuestionTool(),
            SearchWorldKnowledgeTool(
                rag_system=self.rag_system,
                evaluate_tool=evaluate_tool
            ),
            SearchCharacterKnowledgeTool(
                rag_system=self.rag_system,
                character_name=character_name,
                evaluate_tool=evaluate_tool
            ),
            evaluate_tool
        ]
        
        # Cr√©er le prompt
        prompt = create_rag_agent_prompt()
        
        # Cr√©er l'agent
        agent = create_react_agent(
            llm=self.llm,
            tools=tools,
            prompt=prompt
        )
        
        # Cr√©er l'executor
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            max_iterations=4,
            handle_parsing_errors=True,
            max_execution_time=30,
            return_intermediate_steps=True  # Important pour r√©cup√©rer les √©tapes
        )
        
        # Ex√©cuter l'agent
        try:
            result = agent_executor.invoke({
                "character_name": character_name,
                "user_message": user_message,
                "intent": intent or "general"
            })
            
            # Parser le r√©sultat
            final_answer = result.get("output", "{}")
            
            # Extraire les r√©sultats RAG des √©tapes interm√©diaires
            search_performed = False
            search_queries = []
            rag_results = []  # Liste des r√©sultats RAG format√©s
            
            if 'intermediate_steps' in result:
                for action, observation in result['intermediate_steps']:
                    if hasattr(action, 'tool') and hasattr(action, 'tool_input'):
                        # Si c'est une recherche
                        if action.tool in ['search_world', 'search_character']:
                            search_performed = True
                            search_queries.append(action.tool_input)
                            
                            # Parser l'observation qui contient les r√©sultats JSON
                            try:
                                if isinstance(observation, str):
                                    # L'observation est une string JSON
                                    search_results = json.loads(observation)
                                    if isinstance(search_results, list):
                                        # Ajouter chaque r√©sultat √† rag_results
                                        for item in search_results:
                                            if isinstance(item, dict) and 'content' in item:
                                                rag_results.append({
                                                    "content": item.get("content", ""),
                                                    "metadata": {
                                                        "source": item.get("source", "unknown"),
                                                        "type": "character" if "character" in action.tool else "world",
                                                        "importance": "high" if item.get("relevance") == "high" else "medium"
                                                    },
                                                    "relevance": 0.9 if item.get("relevance") == "high" else 0.7,
                                                    "source": item.get("source", "unknown")
                                                })
                            except json.JSONDecodeError:
                                print(f"Erreur parsing observation JSON: {observation}")
            
            # Extraire le JSON de la r√©ponse finale
            json_text = None
            final_answer_match = re.search(r'Final Answer:\s*(\{.*?\})', final_answer, re.DOTALL)
            if final_answer_match:
                json_text = final_answer_match.group(1)
            else:
                json_match = re.search(r'\{[^{}]*\}', final_answer, re.DOTALL)
                if json_match:
                    json_text = json_match.group()
            
            if json_text:
                try:
                    parsed_result = json.loads(json_text)
                    
                    # Retourner les r√©sultats avec les rag_results extraits
                    return {
                        "needs_rag": parsed_result.get("needs_rag", search_performed),
                        "search_performed": search_performed,
                        "rag_results": rag_results,  # Les vrais r√©sultats RAG
                        "relevant_knowledge": [r["content"] for r in rag_results],  # Pour compatibilit√©
                        "search_queries": search_queries,
                        "evaluation": parsed_result.get("evaluation", "none"),
                        "reasoning": parsed_result.get("reasoning", "Recherche effectu√©e" if search_performed else "Aucune recherche n√©cessaire")
                    }
                except json.JSONDecodeError as e:
                    print(f"Erreur de parsing JSON: {e}")
            
            # Fallback avec les r√©sultats RAG extraits
            return {
                "needs_rag": search_performed,
                "search_performed": search_performed,
                "rag_results": rag_results,
                "relevant_knowledge": [r["content"] for r in rag_results],
                "search_queries": search_queries,
                "evaluation": "sufficient" if rag_results else "none",
                "reasoning": "Recherche effectu√©e" if search_performed else "Pas de recherche effectu√©e"
            }
            
        except Exception as e:
            print(f"Erreur dans l'agent RAG ReAct: {e}")
            return {
                "needs_rag": False,
                "search_performed": False,
                "rag_results": [],
                "relevant_knowledge": [],
                "search_queries": [],
                "evaluation": "error",
                "reasoning": f"Erreur: {str(e)}"
            }


def create_react_rag_node(llm_manager: LLMManager):
    """
    Cr√©e un node LangGraph qui utilise l'agent ReAct pour le RAG.
    Remplace assess_rag_need + rag_search + validate_rag_results.
    
    Args:
        llm_manager: Gestionnaire LLM √† utiliser
        
    Returns:
        Fonction node pour LangGraph
    """
    
    @traceable
    def react_rag_node(state: CharacterState) -> CharacterState:
        """Node qui g√®re tout le processus RAG avec un agent ReAct"""
        
        state["processing_steps"].append("react_rag_agent")
        
        # Initialiser le syst√®me RAG
        config = get_config()
        rag_system = EchoForgeRAG(
            data_path=str(config.data_path),
            vector_store_path=str(config.vector_store_path),
            embedding_model=config.embedding_model,
            llm_model=config.llm_model
        )
        
        # Cr√©er l'agent
        agent = ReactRAGAgent(llm_manager, rag_system)
        
        # Traiter avec l'agent
        result = agent.process_rag_need(
            user_message=state["parsed_message"],
            character_name=state["character_name"],
            intent=state["message_intent"],
            conversation_history=state.get("conversation_history", [])
        )
        
        # Mettre √† jour le state avec les r√©sultats
        state["needs_rag_search"] = result["needs_rag"]
        state["rag_query"] = result.get("search_queries", [])
        
        # Convertir les r√©sultats en format attendu
        if result["search_performed"] and result["relevant_knowledge"]:
            rag_results = []
            for i, content in enumerate(result["relevant_knowledge"]):
                rag_results.append({
                    "content": content,
                    "metadata": {"type": "react_search"},
                    "relevance": 1.0 - (i * 0.1),  # Score d√©croissant
                    "source": "react_agent"
                })
            state["rag_results"] = rag_results
            state["relevant_knowledge"] = result["relevant_knowledge"]
        else:
            state["rag_results"] = []
            state["relevant_knowledge"] = []
        
        # Debug info
        state["debug_info"]["react_rag_agent"] = {
            "needs_rag": result["needs_rag"],
            "search_performed": result["search_performed"],
            "queries_count": len(result.get("search_queries", [])),
            "results_count": len(result.get("relevant_knowledge", [])),
            "evaluation": result.get("evaluation", "none"),
            "reasoning": result.get("reasoning", "")
        }
        
        return state
    
    return react_rag_node


# """N≈ìud de recherche RAG."""

# from typing import List, Dict, Any
# from ..state.character_state import CharacterState
# from langsmith import traceable
# from echoforge.core import EchoForgeRAG
# from echoforge.utils.config import get_config

# config = get_config()
# @traceable
# def perform_rag_search(llm_manager):
#     """
#     Effectue une recherche RAG bas√©e sur la requ√™te d√©termin√©e.
    
#     Args:
#         state: √âtat actuel du personnage
        
#     Returns:
#         √âtat mis √† jour avec les r√©sultats RAG
#     """
#     def fn(state: CharacterState) -> CharacterState:
#         state["processing_steps"].append("rag_search")
#         query = state["rag_query"][-1]

#         if state.get("needs_rag_retry"):
#             new_query = _reformulate_query_with_llm(state, previous_query=query, llm_manager=llm_manager)
#             if new_query:
#                 state["rag_query"].append(new_query)
#                 query = new_query
        
#         character_name = state["character_name"]
#         try:
#             rag_system = EchoForgeRAG(
#                     data_path=str(config.data_path),
#                     vector_store_path=str(config.vector_store_path),
#                     embedding_model=config.embedding_model,
#                     llm_model=config.llm_model
#                 )
#             results = []

#             # Recherche dans les connaissances du monde
#             world_context = rag_system.retrieve_world_context(query, top_k=config.top_k_world)
#             for i, content in enumerate(world_context):
#                 results.append({
#                     "content": content,
#                     "metadata": {"type": "world", "importance": "medium"},
#                     "relevance": max(0.8 - i * 0.1, 0.3),  # Score d√©croissant
#                     "source": "world_knowledge"
#                 })
            
#             # Recherche dans les connaissances du personnage
#             character_context = rag_system.retrieve_character_context(
#                 query, character_name.lower(), top_k=config.top_k_character
#             )
#             for i, content in enumerate(character_context):
#                 results.append({
#                     "content": content,
#                     "metadata": {"type": "character", "importance": "high"},
#                     "relevance": max(0.9 - i * 0.1, 0.4),  # Score plus √©lev√© pour le personnage
#                     "source": f"{character_name}_knowledge"
#                 })
            
#             # Trie par pertinence d√©croissante
#             results.sort(key=lambda x: x["relevance"], reverse=True)
            
#         except ImportError as e:
#             print("‚ö†Ô∏è EchoForgeRAG non disponible, utilisation de la simulation")
#             return state
        
#         except Exception as e:
#             print(f"‚ö†Ô∏è Erreur lors de la recherche RAG: {e}")
#             return state
        
#         # Limite √† 5 r√©sultats maximum
#         rag_results = results[:5]
        
#         # Mise √† jour de l'√©tat
#         state["rag_results"].extend(rag_results)
        
#         # Debug info
#         state["debug_info"]["rag_search"] = {
#             "query": query,
#             "results_count": len(rag_results),
#             "top_relevance_score": rag_results[0]["relevance"] if rag_results else 0
#         }
        
#         return state
#     return fn

# def _reformulate_query_with_llm(state: CharacterState, previous_query: str, llm_manager) -> str:
#     """
#     Reformule une requ√™te RAG plus efficace √† partir du message utilisateur,
#     de l‚Äôintention, et du contexte de recherche pr√©c√©dent.
#     """
#     user_msg = state.get("parsed_message") or state.get("user_message", "")
#     intent = state.get("message_intent", "")
#     character_name = state.get("character_name", "le personnage")
#     rag_results = state.get("rag_results", [])
    
#     previous_knowledge = "\n".join(
#         f"- {r['content']}" for r in rag_results[:3]
#     ) if rag_results else "Aucun r√©sultat pertinent pr√©c√©demment trouv√©."

#     prompt = f"""
# Tu es un assistant expert en recherche de connaissances narratives pour un jeu de r√¥le.

# Le personnage s'appelle {character_name}.

# Le joueur a dit : "{user_msg}"
# Intention d√©tect√©e : {intent}
# Ancienne requ√™te utilis√©e : "{previous_query}"

# Voici les r√©sultats pr√©c√©demment trouv√©s :
# {previous_knowledge}

# Tu dois g√©n√©rer une nouvelle requ√™te optimis√©e, plus pr√©cise, qui aiderait le personnage √† trouver des informations pertinentes.

# R√©ponds uniquement par la requ√™te reformul√©e, sans autre texte.
# Si aucune reformulation pertinente n'est possible, r√©ponds exactement : NONE
# """

#     try:
#         new_query = llm_manager.invoke(prompt).strip()
#         if new_query.upper() == "NONE":
#             return None
#         return new_query
#     except Exception as e:
#         state["debug_info"]["query_reformulation_error"] = str(e)
#         return None