import random
from typing import Dict, Any, List
from ..state.character_state import CharacterState
from langsmith import traceable
from echoforge.utils.config import get_config

config = get_config()

@traceable
def generate_simple_response(state: CharacterState) -> CharacterState:
    """
    G√©n√®re une r√©ponse simple bas√©e sur la personnalit√©, sans RAG.
    
    Args:
        state: √âtat actuel du personnage
        
    Returns:
        √âtat mis √† jour avec la r√©ponse g√©n√©r√©e
    """
    state["processing_steps"].append("simple_response_generation")
    
    character_name = state["character_name"]
    personality = state["character_data"]["personality"]
    intent = state["message_intent"]
    emotion = state["character_data"].get("current_emotion", "neutral")
    
    # G√©n√©ration de r√©ponse simple selon l'intention
    response = _generate_personality_response(
        character_name, personality, intent, emotion, state["user_message"]
    )
    
    state["response"] = response
    
    # Debug info
    state["debug_info"]["response_generation"] = {
        "type": "simple",
        "intent_used": intent,
        "emotion_used": emotion,
        "personality_traits_count": len(personality)
    }
    
    return state

@traceable
def generate_response(state: CharacterState) -> CharacterState:
    """
    G√©n√®re une r√©ponse complexe avec ou sans contexte RAG via LLM.
    
    Args:
        state: √âtat actuel du personnage
        
    Returns:
        √âtat mis √† jour avec la r√©ponse g√©n√©r√©e
    """
    state["processing_steps"].append("complex_response_generation")
    
    # G√©n√©ration via LLM avec contexte
    response = _generate_llm_response(state)
    
    state["response"] = response["content"]
    
    # Debug info
    state["debug_info"]["response_generation"] = {
        "type": "llm_generated",
        "rag_results_used": len(state["rag_results"]),
        "context_elements": len(state["relevant_knowledge"]),
        "response_length": len(response["content"]),
        "method": response.get("method", "llm_call"),
        "success": response.get("success", True)
    }
    
    return state

@traceable
def _generate_llm_response(state: CharacterState) -> Dict[str, Any]:
    """
    G√©n√®re une r√©ponse via LLM avec tout le contexte disponible.
    
    Args:
        state: √âtat du personnage avec contexte
        
    Returns:
        Dict avec la r√©ponse et m√©tadonn√©es
    """
    try:
        # Import du syst√®me LLM
        from echoforge.core import EchoForgeRAG
        from echoforge.utils.config import get_config
        
        # R√©cup√©ration de la configuration et du LLM
        config = get_config()
        rag_system = EchoForgeRAG(
            data_path=str(config.data_path),
            vector_store_path=str(config.vector_store_path),
            embedding_model=config.embedding_model,
            llm_provider=config.llm_provider,
            llm_model=config.llm_model
        )
        
        # Construction du prompt complet
        response_prompt = _build_comprehensive_prompt(state)
        
        # Appel au LLM
        llm_response = rag_system.llm.invoke(response_prompt)
        
        # Gestion du type de r√©ponse (string ou AIMessage)
        if isinstance(llm_response, str):
            content = llm_response.strip()
        elif hasattr(llm_response, 'content'):
            content = llm_response.content.strip()
        else:
            content = str(llm_response).strip()
        
        return {
            "content": content,
            "method": "llm_call",
            "success": True,
            "prompt_length": len(response_prompt)
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la g√©n√©ration LLM: {e}")
        # Fallback sur g√©n√©ration simple
        fallback_response = _generate_fallback_response(state)
        return {
            "content": fallback_response,
            "method": "fallback",
            "success": False,
            "error": str(e)
        }


def _build_comprehensive_prompt(state: CharacterState) -> str:
    """
    Construit un prompt complet avec tout le contexte disponible.
    üÜï Version am√©lior√©e avec int√©gration du contexte de m√©moire.
    """
    
    # R√©cup√©ration des donn√©es
    character_name = state["character_name"]
    personality = state["character_data"].get("personality")
    emotion = state["character_data"].get("current_emotion", "neutral")
    user_relation = state["character_data"].get("relation")
    user_message = state["user_message"]
    rag_results = state["rag_results"]
    conversation_history = state.get("conversation_history", [])
    all_triggers = state["character_data"].get("triggers", {}).get("input", {})
    activated = state.get("activated_input_triggers", []) or []
    refused = state.get("refused_input_triggers", []) or []
    
    # üÜï R√©cup√©ration du contexte de m√©moire
    context_summary = state.get("context_summary")
    previous_summaries = state.get("previous_summaries", [])
    total_interactions = state.get("total_interactions", 0)
    memory_integration = state.get("memory_integration", {})
    
    # Format des intentions activ√©es
    def format_trigger_list(trigger_names):
        return "\n".join([
            f"- {trigger}: {all_triggers[trigger].get('trigger')} ‚Üí effet attendu : {all_triggers[trigger].get('effect')}"
            for trigger in trigger_names if trigger in all_triggers
        ]) or "Aucune"
    
    def format_refused_trigger_list(refused_dict : list):
        return "\n".join([
            f"- {trigger.get('trigger')} ‚Üí refus√© car : {trigger.get('reason_refused')}"
            for trigger in refused_dict
        ]) or "Aucune"
    
    # Construction des sections du prompt
    
    # 1. Identit√© du personnage
    identity_section = f"""Tu es {character_name}.
PERSONNALIT√â: {_format_personality(personality)}
√âMOTION ACTUELLE: {emotion}
NIVEAU RELATION AVEC LE PERSONNAGE JOUEUR (entre -10 et 10) : {user_relation}"""

    # üÜï 2. Section de contexte de m√©moire
    memory_section = ""
    if context_summary or previous_summaries:
        memory_section = f"""
CONTEXTE DE M√âMOIRE (Total: {total_interactions} interactions):
"""
        
        if context_summary:
            memory_section += f"""
R√âSUM√â CONTEXTUEL:
{context_summary}
"""
        
        if previous_summaries and len(previous_summaries) > 0:
            memory_section += f"""
R√âSUM√âS PR√âC√âDENTS ({len(previous_summaries)} disponibles):
"""
            for i, summary in enumerate(previous_summaries[:2]):  # Limite √† 2 r√©sum√©s pour le prompt
                summary_text = summary.get("text", "")
                messages_count = summary.get("messages_count", 0)
                memory_section += f"‚Ä¢ R√©sum√© {i+1} ({messages_count} √©changes): {summary_text}\n"
        
        memory_section += f"""
INT√âGRATION M√âMOIRE: {'Activ√©e' if memory_integration.get('should_integrate', False) else 'D√©sactiv√©e'}
"""

    # 3. Contexte RAG si disponible
    rag_section = ""
    if rag_results:
        context_items = []
        for result in rag_results[:3]:  # Limite √† 3 r√©sultats les plus pertinents
            context_items.append(f"- {result['content']} (pertinence: {result['relevance']:.2f})")
        
        rag_section = f"""
CONNAISSANCES PERTINENTES:
{chr(10).join(context_items)}"""

    # 4. Historique de conversation r√©cent
    history_section = ""
    if conversation_history:
        recent_history = conversation_history[-3:]  # 3 derniers √©changes
        history_items = []
        for exchange in recent_history:
            if isinstance(exchange, dict):
                if "user" in exchange and "assistant" in exchange:
                    history_items.append(f"Utilisateur: {exchange['user']}")
                    history_items.append(f"Toi: {exchange['assistant']}")
                elif exchange.get("role") == "user":
                    history_items.append(f"Utilisateur: {exchange['content']}")
                elif exchange.get("role") == "assistant":
                    history_items.append(f"Toi: {exchange['content']}")
        
        if history_items:
            history_section = f"""
HISTORIQUE R√âCENT DE CETTE SESSION:
{chr(10).join(history_items)}"""

    # 5. Section sur les intentions d√©tect√©es
    intent_section = f"""
INTENTIONS D√âTECT√âES DANS LE MESSAGE DU JOUEUR :
- Intentions activ√©es :
{format_trigger_list(activated)}

- Intentions non activ√©es (refus√©es ou ignor√©es) :
{format_refused_trigger_list(refused)}
"""

    # 6. Instructions sp√©cifiques avec int√©gration m√©moire et restrictions
    memory_instructions = ""
    if context_summary or previous_summaries:
        memory_instructions = f"""
8. Utilise le contexte de m√©moire ci-dessus pour maintenir la coh√©rence avec les interactions pass√©es.
9. Si tu mentionnes des √©v√©nements pass√©s, assure-toi qu'ils sont coh√©rents avec le contexte de m√©moire.
10. Adapte ton niveau de familiarit√© selon l'historique des interactions ({total_interactions} interactions totales).
"""

    # 7. Contraintes suppl√©mentaires
    constraint_section = f"""
CONTRAINTES:
- Tu NE DOIS PAS proposer ou initier d'actions ou d√©placements non pr√©vus par les intentions activ√©es.
- Tu NE DOIS PAS inventer de nouvelles m√©caniques ou interactions qui ne sont pas d√©crites dans les intentions activ√©es.
- Tu PEUX r√©agir uniquement en fonction des intentions activ√©es list√©es ci-dessus.
- Si le joueur propose une action non pr√©vue, ignore-la poliment ou refuse avec coh√©rence selon ta personnalit√©.
"""

    instructions_section = f"""
MESSAGE ACTUEL DE L'UTILISATEUR: "{user_message}"

INSTRUCTIONS:
1. Reste parfaitement en personnage comme {character_name}.
2. Utilise ta personnalit√© et ton √©motion actuelle ({emotion}).
3. Si tu as des connaissances pertinentes ci-dessus, int√®gre-les naturellement.
4. Tiens compte de l'historique de conversation pour la coh√©rence.
5. Si tu fais des actions physiques, mets-les entre *ast√©risques*.
6. R√©ponds en fran√ßais de mani√®re authentique √† ton personnage.
7. Tu ne dois r√©agir qu‚Äôen fonction des intentions activ√©es d√©tect√©es.
{memory_instructions}
{constraint_section}

R√âPONSE:"""

    # === Assemblage final avec m√©moire ===
    full_prompt = f"""{identity_section}{memory_section}{rag_section}{history_section}
{intent_section}
{instructions_section}"""
    
    return full_prompt


def _format_personality(personality: Dict[str, Any]) -> str:
    """Formate les traits de personnalit√© pour le prompt."""
    if not personality:
        return "Personnalit√© standard"
    
    if isinstance(personality, dict):
        traits = []
        for key, value in personality.items():
            if isinstance(value, (int, float)):
                if value > 0.7:
                    traits.append(f"{key} √©lev√©")
                elif value < 0.3:
                    traits.append(f"{key} faible")
            else:
                traits.append(f"{key}: {value}")
        return ", ".join(traits) if traits else "√âquilibr√©"
    
    return str(personality)


def _generate_fallback_response(state: CharacterState) -> str:
    """G√©n√®re une r√©ponse de fallback si le LLM √©choue."""
    
    character_name = state["character_name"]
    intent = state["message_intent"]
    emotion = state["character_data"].get("current_emotion", "neutral")
    
    # Templates de fallback par intention
    fallback_templates = {
        "question": [
            f"C'est une question int√©ressante... Laissez-moi r√©fl√©chir.",
            f"Hmm, votre question me fait r√©fl√©chir.",
            f"Interessant que vous me demandiez cela."
        ],
        "greeting": [
            f"Bonjour ! Comment puis-je vous aider ?",
            f"Salutations ! Que puis-je faire pour vous ?",
            f"Bienvenue ! En quoi puis-je vous √™tre utile ?"
        ],
        "request": [
            f"Je vais voir ce que je peux faire pour vous.",
            f"Votre demande m√©rite consid√©ration.",
            f"Laissez-moi r√©fl√©chir √† votre requ√™te."
        ],
        "general": [
            f"Je vous √©coute attentivement.",
            f"Continuez, vous avez mon attention.",
            f"Int√©ressant, dites-moi en plus."
        ]
    }
    
    # S√©lection d'un template appropri√©
    templates = fallback_templates.get(intent, fallback_templates["general"])
    response = random.choice(templates)
    
    # Ajustement selon l'√©motion
    if emotion == "sad":
        response += " *soupire*"
    elif emotion == "happy":
        response += " üòä"
    elif emotion == "angry":
        response = response.replace("!", ".")
    
    return response


def _generate_personality_response(
    character_name: str, 
    personality: Dict[str, Any], 
    intent: str, 
    emotion: str, 
    user_message: str
) -> str:
    """G√©n√®re une r√©ponse simple bas√©e uniquement sur la personnalit√©."""
    
    # Templates de r√©ponses par personnage et intention
    response_templates = {
        "martine": {
            "greeting": [
                "Bonjour, citoyen ! Comment puis-je vous aider aujourd'hui ?",
                "Salutations ! En tant que maire, je suis √† votre service.",
                "Bienvenue ! Que puis-je faire pour notre communaut√© ?"
            ],
            "farewell": [
                "Au revoir, citoyen. Que votre journ√©e soit prosp√®re !",
                "Prenez soin de vous et de notre belle √Æle !",
                "√Ä bient√¥t ! N'h√©sitez pas √† revenir me voir."
            ],
            "general": [
                "En tant que maire, je veille sur tous les habitants de notre √Æle.",
                "Notre communaut√© est ma priorit√© absolue, citoyen.",
                "Parlons de ce qui vous pr√©occupe."
            ]
        },
        "claude": {
            "greeting": [
                "Salut ! Mon marteau et moi sommes √† votre service.",
                "Bonjour ! Besoin de quelque chose de r√©par√© ?",
                "Hey ! L'atelier est ouvert, que puis-je forger pour vous ?"
            ],
            "farewell": [
                "√Ä plus ! Si √ßa casse, vous savez o√π me trouver !",
                "Prenez soin de vos outils !",
                "Au revoir ! Que le m√©tal soit avec vous !"
            ],
            "general": [
                "Je peux r√©parer √† peu pr√®s n'importe quoi, mais √ßa se n√©gocie.",
                "Mon atelier a vu passer bien des objets √©tranges...",
                "Le m√©tal ne ment jamais, contrairement aux gens."
            ]
        },
        "azzedine": {
            "greeting": [
                "Bonjour ! Admirez-vous ma derni√®re cr√©ation ?",
                "Salut ! L'art textile vous int√©resse-t-il ?",
                "Bienvenue dans mon atelier de beaut√© !"
            ],
            "farewell": [
                "Au revoir ! Que la beaut√© vous accompagne !",
                "Partez avec style !",
                "√Ä bient√¥t ! Revenez quand vous aurez d√©velopp√© votre go√ªt esth√©tique."
            ],
            "general": [
                "La beaut√© est dans les d√©tails, et je suis un perfectionniste.",
                "Mes tissus sont d'une qualit√© incomparable sur cette √Æle.",
                "L'art v√©ritable demande de la patience et de l'exigence."
            ]
        },
        "roberte": {
            "greeting": [
                "Bonjour ! J'esp√®re que vous avez faim !",
                "Salut ! La cuisine sent bon aujourd'hui, n'est-ce pas ?",
                "Bienvenue ! Venez-vous pour mes fameux cookies ?"
            ],
            "farewell": [
                "Au revoir ! Revenez quand vous aurez faim !",
                "√Ä bient√¥t ! Mes cookies vous attendront !",
                "Prenez soin de vous et mangez bien !"
            ],
            "general": [
                "Ma cuisine est ma fiert√©, ne me d√©rangez pas pendant que je travaille !",
                "Un bon repas r√©chauffe le c≈ìur et l'√¢me.",
                "Mes cookies sont les meilleurs de l'√Æle, mais il faut les m√©riter !"
            ]
        }
    }
    
    # S√©lection du template appropri√©
    character_templates = response_templates.get(character_name.lower(), response_templates["martine"])
    intent_templates = character_templates.get(intent, character_templates["general"])
    
    # S√©lection al√©atoire d'une r√©ponse
    response = random.choice(intent_templates)
    
    return response